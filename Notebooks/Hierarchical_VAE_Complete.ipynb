{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMxNo3t7twVHB0muyq+qlVf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MichaelMatley/Hierarchial-VAE-Emergent/blob/main/Hierarchical_VAE_Complete.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hierarchical Multi-Scale Latent VAE"
      ],
      "metadata": {
        "id": "mBjEZ1z-jhGd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Theoretical for emergent representation learning\n",
        "- Stochastic bottleneck forces the model to develop a compressed “language” rather than just memorising pattern\n",
        "\n",
        "- Complete Colab Notebook: Hierarchical VAE for Emergent Representation Learning"
      ],
      "metadata": {
        "id": "c-4-B0UIiguZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: ARHITECRE, TRAINING, & β-ANNEALING."
      ],
      "metadata": {
        "id": "nH7wv_cQhwMk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 1: Environment Setup"
      ],
      "metadata": {
        "id": "9_t83mdefme-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnmqgKZoffFy"
      },
      "outputs": [],
      "source": [
        "# Check hardware\n",
        "import torch\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "\n",
        "# Install dependencies\n",
        "!pip install biopython umap-learn scikit-learn matplotlib seaborn tqdm -q\n",
        "\n",
        "print(\"✓ Environment ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 2: Import Libraries"
      ],
      "metadata": {
        "id": "rKes7C2Cf0_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import umap\n",
        "\n",
        "from Bio import SeqIO\n",
        "from Bio.Seq import Seq\n",
        "from Bio.SeqRecord import SeqRecord\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "\n",
        "print(\"✓ Libraries imported\")"
      ],
      "metadata": {
        "id": "QZ-CPMaEf5rk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 3: DNA Encoding Utilities"
      ],
      "metadata": {
        "id": "I1MHyLnNgAGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DNAEncoder:\n",
        "    \"\"\"\n",
        "    Convert DNA sequences to numerical representations.\n",
        "    Supports one-hot encoding with proper handling of ambiguous bases.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def one_hot_encode(sequence):\n",
        "        \"\"\"\n",
        "        One-hot encoding: A=[1,0,0,0], C=[0,1,0,0], G=[0,0,1,0], T=[0,0,0,1]\n",
        "        Returns: (4, seq_length) array\n",
        "        \"\"\"\n",
        "        mapping = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
        "        seq_upper = sequence.upper()\n",
        "\n",
        "        encoded = np.zeros((4, len(seq_upper)), dtype=np.float32)\n",
        "\n",
        "        for idx, nucleotide in enumerate(seq_upper):\n",
        "            if nucleotide in mapping:\n",
        "                encoded[mapping[nucleotide], idx] = 1.0\n",
        "            # Ambiguous bases (N, etc.) result in all-zero columns\n",
        "\n",
        "        return encoded\n",
        "\n",
        "    @staticmethod\n",
        "    def decode_one_hot(encoded_array):\n",
        "        \"\"\"\n",
        "        Convert one-hot encoded array back to DNA sequence.\n",
        "        Args:\n",
        "            encoded_array: (4, seq_length) array\n",
        "        Returns:\n",
        "            DNA sequence string\n",
        "        \"\"\"\n",
        "        bases = 'ACGT'\n",
        "        sequence = ''.join([bases[np.argmax(encoded_array[:, i])]\n",
        "                           for i in range(encoded_array.shape[1])])\n",
        "        return sequence\n",
        "\n",
        "\n",
        "# Test the encoder\n",
        "test_seq = \"ATCGATCGATCGNNNATCG\"\n",
        "encoded = DNAEncoder.one_hot_encode(test_seq)\n",
        "decoded = DNAEncoder.decode_one_hot(encoded)\n",
        "\n",
        "print(f\"Original:  {test_seq}\")\n",
        "print(f\"Decoded:   {decoded}\")\n",
        "print(f\"Encoding shape: {encoded.shape}\")\n",
        "print(\"✓ DNA encoder working\")"
      ],
      "metadata": {
        "id": "Tb_9IYt4gLng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 4: Dataset Class"
      ],
      "metadata": {
        "id": "O478vRO6gN2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GenomicDataset(Dataset):\n",
        "    \"\"\"\n",
        "    PyTorch Dataset for genomic sequences.\n",
        "    Extracts fixed-length windows from FASTA files.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, fasta_file, window_size=1024, stride=512,\n",
        "                 max_samples=None, filter_n_threshold=0.1):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            fasta_file: Path to FASTA file\n",
        "            window_size: Length of sequence windows\n",
        "            stride: Sliding window stride\n",
        "            max_samples: Maximum number of samples to extract (None = all)\n",
        "            filter_n_threshold: Maximum proportion of N bases allowed\n",
        "        \"\"\"\n",
        "        self.window_size = window_size\n",
        "        self.stride = stride\n",
        "        self.sequences = []\n",
        "\n",
        "        print(f\"Loading sequences from {fasta_file}...\")\n",
        "\n",
        "        for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
        "            sequence = str(record.seq).upper()\n",
        "\n",
        "            # Sliding window extraction\n",
        "            for i in range(0, len(sequence) - window_size + 1, stride):\n",
        "                if max_samples and len(self.sequences) >= max_samples:\n",
        "                    break\n",
        "\n",
        "                chunk = sequence[i:i + window_size]\n",
        "\n",
        "                # Filter sequences with too many ambiguous bases\n",
        "                n_count = chunk.count('N')\n",
        "                if n_count / len(chunk) <= filter_n_threshold:\n",
        "                    self.sequences.append(chunk)\n",
        "\n",
        "            if max_samples and len(self.sequences) >= max_samples:\n",
        "                break\n",
        "\n",
        "        print(f\"✓ Created dataset: {len(self.sequences)} sequences of {window_size} bp\")\n",
        "        print(f\"  Overlap: {window_size - stride} bp\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sequence = self.sequences[idx]\n",
        "\n",
        "        # One-hot encode\n",
        "        encoded = DNAEncoder.one_hot_encode(sequence)\n",
        "\n",
        "        # Flatten: (4, 1024) -> (4096,)\n",
        "        encoded_flat = encoded.flatten()\n",
        "\n",
        "        return torch.tensor(encoded_flat, dtype=torch.float32)\n",
        "\n",
        "    def get_sequence(self, idx):\n",
        "        \"\"\"Return raw sequence string\"\"\"\n",
        "        return self.sequences[idx]\n",
        "\n",
        "\n",
        "def create_synthetic_genome(length=5_000_000, output_file='synthetic_genome.fasta'):\n",
        "    \"\"\"\n",
        "    Generate synthetic genome with realistic base composition.\n",
        "    C. elegans has ~36% GC content.\n",
        "    \"\"\"\n",
        "    # Weighted base selection (approximating C. elegans)\n",
        "    bases = ['A', 'T', 'G', 'C']\n",
        "    weights = [0.32, 0.32, 0.18, 0.18]  # ~36% GC\n",
        "\n",
        "    sequence = ''.join(np.random.choice(bases, size=length, p=weights))\n",
        "\n",
        "    record = SeqRecord(\n",
        "        Seq(sequence),\n",
        "        id=\"synthetic_chr\",\n",
        "        description=f\"Synthetic {length/1e6:.1f}Mb genome for testing\"\n",
        "    )\n",
        "\n",
        "    SeqIO.write(record, output_file, \"fasta\")\n",
        "    print(f\"✓ Created synthetic genome: {output_file} ({length/1e6:.1f} Mb)\")\n",
        "\n",
        "    return output_file\n",
        "\n",
        "\n",
        "# Create synthetic data for testing\n",
        "synthetic_file = create_synthetic_genome(length=5_000_000)  # 5 Mb\n",
        "\n",
        "# Create dataset\n",
        "dataset = GenomicDataset(\n",
        "    fasta_file=synthetic_file,\n",
        "    window_size=1024,\n",
        "    stride=512,\n",
        "    max_samples=100_000  # Limit to 100k samples for faster training\n",
        ")\n",
        "\n",
        "print(f\"\\nSample shape: {dataset[0].shape}\")\n",
        "print(f\"Sample stats - Min: {dataset[0].min():.2f}, Max: {dataset[0].max():.2f}\")"
      ],
      "metadata": {
        "id": "S6N-qViKgS-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 5: Hierarchical VAE Architecture"
      ],
      "metadata": {
        "id": "tELYKKPCgbzt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HierarchicalVAE(nn.Module):\n",
        "    \"\"\"\n",
        "    Multi-scale Variational Autoencoder with hierarchical latent spaces.\n",
        "\n",
        "    Architecture:\n",
        "        Input (4096) -> Encoder -> 3 latent spaces [256, 512, 1024]\n",
        "        Latent spaces -> Decoder -> Reconstruction (4096)\n",
        "\n",
        "    The model learns to represent data at multiple levels of abstraction:\n",
        "        - Level 1 (256d): Most abstract, compressed representation\n",
        "        - Level 2 (512d): Intermediate features\n",
        "        - Level 3 (1024d): Fine-grained details\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim=4096, latent_dims=[256, 512, 1024], dropout=0.3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.latent_dims = latent_dims\n",
        "\n",
        "        # ========================\n",
        "        # ENCODER PATHWAY\n",
        "        # ========================\n",
        "\n",
        "        # Stage 1: Input -> 2048\n",
        "        self.enc1 = nn.Sequential(\n",
        "            nn.Linear(input_dim, 2048),\n",
        "            nn.LayerNorm(2048),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "        # Stage 2: 2048 -> 1024\n",
        "        self.enc2 = nn.Sequential(\n",
        "            nn.Linear(2048, 1024),\n",
        "            nn.LayerNorm(1024),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "        # Stage 3: 1024 -> 512 (deepest layer)\n",
        "        self.enc3 = nn.Sequential(\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.LayerNorm(512),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "        # ========================\n",
        "        # LATENT SPACE PROJECTIONS\n",
        "        # ========================\n",
        "\n",
        "        # Latent level 1: From deepest layer (most abstract)\n",
        "        self.z1_mu = nn.Linear(512, latent_dims[0])\n",
        "        self.z1_logvar = nn.Linear(512, latent_dims[0])\n",
        "\n",
        "        # Latent level 2: From intermediate layer\n",
        "        self.z2_mu = nn.Linear(1024, latent_dims[1])\n",
        "        self.z2_logvar = nn.Linear(1024, latent_dims[1])\n",
        "\n",
        "        # Latent level 3: From shallow layer (fine details)\n",
        "        self.z3_mu = nn.Linear(2048, latent_dims[2])\n",
        "        self.z3_logvar = nn.Linear(2048, latent_dims[2])\n",
        "\n",
        "        # ========================\n",
        "        # DECODER PATHWAY\n",
        "        # ========================\n",
        "\n",
        "        total_latent_dim = sum(latent_dims)  # 256 + 512 + 1024 = 1792\n",
        "\n",
        "        # Stage 1: Concatenated latents -> 512\n",
        "        self.dec1 = nn.Sequential(\n",
        "            nn.Linear(total_latent_dim, 512),\n",
        "            nn.LayerNorm(512),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "        # Stage 2: 512 -> 1024\n",
        "        self.dec2 = nn.Sequential(\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.LayerNorm(1024),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "        # Stage 3: 1024 -> 2048\n",
        "        self.dec3 = nn.Sequential(\n",
        "            nn.Linear(1024, 2048),\n",
        "            nn.LayerNorm(2048),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "        # Output layer: 2048 -> 4096 (reconstruction)\n",
        "        self.output = nn.Linear(2048, input_dim)\n",
        "\n",
        "        # Initialize weights\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        \"\"\"Xavier initialization for better gradient flow\"\"\"\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.xavier_uniform_(module.weight)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        \"\"\"\n",
        "        Reparameterization trick: z = mu + std * epsilon\n",
        "        Allows gradients to flow through sampling operation.\n",
        "        \"\"\"\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def encode(self, x):\n",
        "        \"\"\"\n",
        "        Encode input into hierarchical latent representations.\n",
        "\n",
        "        Returns:\n",
        "            latents: Tuple of (z1, z2, z3) sampled latent vectors\n",
        "            params: List of (mu, logvar) tuples for KL divergence calculation\n",
        "        \"\"\"\n",
        "        # Forward through encoder stages\n",
        "        h1 = self.enc1(x)      # (batch, 2048)\n",
        "        h2 = self.enc2(h1)     # (batch, 1024)\n",
        "        h3 = self.enc3(h2)     # (batch, 512)\n",
        "\n",
        "        # Extract latent parameters from each level\n",
        "        # Level 1: Most abstract (from deepest layer)\n",
        "        z1_mu = self.z1_mu(h3)\n",
        "        z1_logvar = self.z1_logvar(h3)\n",
        "        z1 = self.reparameterize(z1_mu, z1_logvar)\n",
        "\n",
        "        # Level 2: Intermediate\n",
        "        z2_mu = self.z2_mu(h2)\n",
        "        z2_logvar = self.z2_logvar(h2)\n",
        "        z2 = self.reparameterize(z2_mu, z2_logvar)\n",
        "\n",
        "        # Level 3: Fine details (from shallowest layer)\n",
        "        z3_mu = self.z3_mu(h1)\n",
        "        z3_logvar = self.z3_logvar(h1)\n",
        "        z3 = self.reparameterize(z3_mu, z3_logvar)\n",
        "\n",
        "        latents = (z1, z2, z3)\n",
        "        params = [(z1_mu, z1_logvar), (z2_mu, z2_logvar), (z3_mu, z3_logvar)]\n",
        "\n",
        "        return latents, params\n",
        "\n",
        "    def decode(self, latents):\n",
        "        \"\"\"\n",
        "        Decode from hierarchical latent space to reconstruction.\n",
        "\n",
        "        Args:\n",
        "            latents: Tuple of (z1, z2, z3)\n",
        "        \"\"\"\n",
        "        # Concatenate all latent levels\n",
        "        z = torch.cat(latents, dim=-1)  # (batch, 1792)\n",
        "\n",
        "        # Decode through stages\n",
        "        h = self.dec1(z)\n",
        "        h = self.dec2(h)\n",
        "        h = self.dec3(h)\n",
        "\n",
        "        return self.output(h)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Full forward pass: encode -> sample -> decode\n",
        "\n",
        "        Returns:\n",
        "            reconstruction: Reconstructed input\n",
        "            latents: Sampled latent vectors\n",
        "            params: Distribution parameters for loss calculation\n",
        "        \"\"\"\n",
        "        latents, params = self.encode(x)\n",
        "        reconstruction = self.decode(latents)\n",
        "\n",
        "        return reconstruction, latents, params\n",
        "\n",
        "\n",
        "# Instantiate model\n",
        "model = HierarchicalVAE(\n",
        "    input_dim=4096,\n",
        "    latent_dims=[256, 512, 1024],\n",
        "    dropout=0.3\n",
        ")\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"✓ Model created\")\n",
        "print(f\"  Total parameters: {total_params:,}\")\n",
        "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
        "print(f\"  Latent space dimensions: {model.latent_dims}\")\n",
        "print(f\"  Total latent dimension: {sum(model.latent_dims)}\")"
      ],
      "metadata": {
        "id": "v2gNHiDHgfwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 6: Loss Functions"
      ],
      "metadata": {
        "id": "rMIIf_F4gqP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vae_loss_function(recon_x, x, latent_params, beta=1.0, kl_weights=[1.0, 1.0, 1.0]):\n",
        "    \"\"\"\n",
        "    VAE loss = Reconstruction loss + β * KL divergence\n",
        "\n",
        "    Args:\n",
        "        recon_x: Reconstructed input\n",
        "        x: Original input\n",
        "        latent_params: List of (mu, logvar) tuples for each latent level\n",
        "        beta: KL divergence weighting factor (β-VAE)\n",
        "        kl_weights: Per-level KL weights (for hierarchical control)\n",
        "\n",
        "    Returns:\n",
        "        total_loss: Combined loss\n",
        "        recon_loss: Reconstruction term\n",
        "        kl_loss: KL divergence term\n",
        "        kl_per_level: KL divergence for each hierarchical level\n",
        "    \"\"\"\n",
        "    # Reconstruction loss (MSE)\n",
        "    recon_loss = F.mse_loss(recon_x, x, reduction='sum') / x.size(0)\n",
        "\n",
        "    # KL divergence for each latent level\n",
        "    kl_per_level = []\n",
        "    kl_loss = 0\n",
        "\n",
        "    for idx, (mu, logvar) in enumerate(latent_params):\n",
        "        # KL(N(mu, sigma) || N(0, 1))\n",
        "        kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=-1)\n",
        "        kl = kl.mean()  # Average over batch\n",
        "\n",
        "        kl_per_level.append(kl.item())\n",
        "        kl_loss += kl_weights[idx] * kl\n",
        "\n",
        "    # Total loss\n",
        "    total_loss = recon_loss + beta * kl_loss\n",
        "\n",
        "    return total_loss, recon_loss, kl_loss, kl_per_level\n",
        "\n",
        "\n",
        "print(\"✓ Loss function defined\")"
      ],
      "metadata": {
        "id": "5dKzMuVHgtAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 7: Training Loop"
      ],
      "metadata": {
        "id": "sxU7-hJmgzv8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_hierarchical_vae(model, train_loader, val_loader,\n",
        "                          epochs=100, lr=1e-3,\n",
        "                          beta_schedule=None,\n",
        "                          device='cuda'):\n",
        "    \"\"\"\n",
        "    Training loop with β-annealing and comprehensive monitoring.\n",
        "\n",
        "    Args:\n",
        "        beta_schedule: Function that returns beta value given epoch number\n",
        "                      If None, uses constant β=1.0\n",
        "    \"\"\"\n",
        "    model.to(device)\n",
        "\n",
        "    # Optimizer with weight decay for regularization\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n",
        "\n",
        "    # Learning rate scheduler: Cosine annealing with warm restarts\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "        optimizer, T_0=10, T_mult=2, eta_min=1e-6\n",
        "    )\n",
        "\n",
        "    # Training history\n",
        "    history = {\n",
        "        'train_loss': [], 'train_recon': [], 'train_kl': [],\n",
        "        'val_loss': [], 'val_recon': [], 'val_kl': [],\n",
        "        'kl_level1': [], 'kl_level2': [], 'kl_level3': [],\n",
        "        'beta_values': []\n",
        "    }\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "    patience = 15\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Starting training on {device}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Determine β value for this epoch\n",
        "        if beta_schedule is not None:\n",
        "            beta = beta_schedule(epoch)\n",
        "        else:\n",
        "            beta = 1.0\n",
        "\n",
        "        history['beta_values'].append(beta)\n",
        "\n",
        "        # ==================\n",
        "        # TRAINING PHASE\n",
        "        # ==================\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_recon = 0\n",
        "        train_kl = 0\n",
        "        kl_levels = [0, 0, 0]\n",
        "\n",
        "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\")\n",
        "\n",
        "        for batch_idx, batch in enumerate(pbar):\n",
        "            x = batch.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            recon, latents, params = model(x)\n",
        "\n",
        "            # Compute loss\n",
        "            loss, recon_loss, kl_loss, kl_per_level = vae_loss_function(\n",
        "                recon, x, params, beta=beta\n",
        "            )\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            # Accumulate metrics\n",
        "            train_loss += loss.item()\n",
        "            train_recon += recon_loss.item()\n",
        "            train_kl += kl_loss.item()\n",
        "            for i in range(3):\n",
        "                kl_levels[i] += kl_per_level[i]\n",
        "\n",
        "            # Update progress bar\n",
        "            pbar.set_postfix({\n",
        "                'loss': f'{loss.item():.4f}',\n",
        "                'recon': f'{recon_loss.item():.4f}',\n",
        "                'kl': f'{kl_loss.item():.4f}',\n",
        "                'β': f'{beta:.3f}'\n",
        "            })\n",
        "\n",
        "        # Average training metrics\n",
        "        n_train = len(train_loader)\n",
        "        avg_train_loss = train_loss / n_train\n",
        "        avg_train_recon = train_recon / n_train\n",
        "        avg_train_kl = train_kl / n_train\n",
        "        avg_kl_levels = [kl / n_train for kl in kl_levels]\n",
        "\n",
        "        # ==================\n",
        "        # VALIDATION PHASE\n",
        "        # ==================\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        val_recon = 0\n",
        "        val_kl = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                x = batch.to(device)\n",
        "\n",
        "                recon, latents, params = model(x)\n",
        "                loss, recon_loss, kl_loss, _ = vae_loss_function(\n",
        "                    recon, x, params, beta=beta\n",
        "                )\n",
        "\n",
        "                val_loss += loss.item()\n",
        "                val_recon += recon_loss.item()\n",
        "                val_kl += kl_loss.item()\n",
        "\n",
        "        # Average validation metrics\n",
        "        n_val = len(val_loader)\n",
        "        avg_val_loss = val_loss / n_val\n",
        "        avg_val_recon = val_recon / n_val\n",
        "        avg_val_kl = val_kl / n_val\n",
        "\n",
        "        # Update history\n",
        "        history['train_loss'].append(avg_train_loss)\n",
        "        history['train_recon'].append(avg_train_recon)\n",
        "        history['train_kl'].append(avg_train_kl)\n",
        "        history['val_loss'].append(avg_val_loss)\n",
        "        history['val_recon'].append(avg_val_recon)\n",
        "        history['val_kl'].append(avg_val_kl)\n",
        "        history['kl_level1'].append(avg_kl_levels[0])\n",
        "        history['kl_level2'].append(avg_kl_levels[1])\n",
        "        history['kl_level3'].append(avg_kl_levels[2])\n",
        "\n",
        "        # Learning rate scheduling\n",
        "        scheduler.step()\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "        # Print epoch summary\n",
        "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
        "        print(f\"  Train Loss: {avg_train_loss:.4f} | Recon: {avg_train_recon:.4f} | KL: {avg_train_kl:.4f}\")\n",
        "        print(f\"  Val Loss:   {avg_val_loss:.4f} | Recon: {avg_val_recon:.4f} | KL: {avg_val_kl:.4f}\")\n",
        "        print(f\"  KL Levels:  L1={avg_kl_levels[0]:.2f} | L2={avg_kl_levels[1]:.2f} | L3={avg_kl_levels[2]:.2f}\")\n",
        "        print(f\"  LR: {current_lr:.2e} | β: {beta:.3f}\")\n",
        "\n",
        "        # Early stopping check\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            patience_counter = 0\n",
        "\n",
        "            # Save best model\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'train_loss': avg_train_loss,\n",
        "                'val_loss': avg_val_loss,\n",
        "                'history': history\n",
        "            }, 'best_hierarchical_vae.pth')\n",
        "\n",
        "            print(f\"  ✓ Best model saved (val_loss: {best_val_loss:.4f})\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            print(f\"  Patience: {patience_counter}/{patience}\")\n",
        "\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
        "            print(f\"{'='*60}\\n\")\n",
        "            break\n",
        "\n",
        "    print(\"\\n✓ Training complete\")\n",
        "    return history\n",
        "\n",
        "\n",
        "print(\"✓ Training function defined\")"
      ],
      "metadata": {
        "id": "u2DspUrRg7U6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 8: β-Annealing Schedule"
      ],
      "metadata": {
        "id": "gqUIVZXLhASe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def beta_annealing_schedule(epoch, warmup_epochs=20, max_beta=1.0, mode='linear'):\n",
        "    \"\"\"\n",
        "    β-annealing for VAE training.\n",
        "    Start with β=0 (pure autoencoder) and gradually increase.\n",
        "\n",
        "    Modes:\n",
        "        'linear': Linear increase from 0 to max_beta\n",
        "        'cyclical': Cyclical annealing (multiple cycles)\n",
        "        'constant': No annealing, use max_beta throughout\n",
        "    \"\"\"\n",
        "    if mode == 'constant':\n",
        "        return max_beta\n",
        "\n",
        "    elif mode == 'linear':\n",
        "        if epoch < warmup_epochs:\n",
        "            return (epoch / warmup_epochs) * max_beta\n",
        "        return max_beta\n",
        "\n",
        "    elif mode == 'cyclical':\n",
        "        cycle_length = 20\n",
        "        cycle_progress = (epoch % cycle_length) / cycle_length\n",
        "        return cycle_progress * max_beta\n",
        "\n",
        "    return max_beta\n",
        "\n",
        "\n",
        "# Test the schedule\n",
        "epochs_test = 50\n",
        "betas = [beta_annealing_schedule(e, warmup_epochs=20, mode='linear') for e in range(epochs_test)]\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(betas, linewidth=2)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('β value')\n",
        "plt.title('β-Annealing Schedule (Linear Warmup)')\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"✓ β-annealing schedule defined\")"
      ],
      "metadata": {
        "id": "1Qiye9Vtg_-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 9: Create Data Loaders and Train"
      ],
      "metadata": {
        "id": "gsB6l6M8hPWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = int(0.1 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(\n",
        "    dataset,\n",
        "    [train_size, val_size, test_size],\n",
        "    generator=torch.Generator().manual_seed(42)\n",
        ")\n",
        "\n",
        "# Create data loaders\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
        "                         num_workers=2, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n",
        "                       num_workers=2, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n",
        "                        num_workers=2, pin_memory=True)\n",
        "\n",
        "print(f\"Dataset splits:\")\n",
        "print(f\"  Train: {len(train_dataset):,} samples\")\n",
        "print(f\"  Val:   {len(val_dataset):,} samples\")\n",
        "print(f\"  Test:  {len(test_dataset):,} samples\")\n",
        "print(f\"  Batch size: {batch_size}\")\n",
        "print(f\"  Batches per epoch: {len(train_loader):,}\\n\")\n",
        "\n",
        "# Train the model\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "history = train_hierarchical_vae(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    epochs=100,\n",
        "    lr=1e-3,\n",
        "    beta_schedule=lambda epoch: beta_annealing_schedule(epoch, warmup_epochs=20, mode='linear'),\n",
        "    device=device\n",
        ")"
      ],
      "metadata": {
        "id": "rCx4JhiLhXvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Latent Space Analysis & Visualization section"
      ],
      "metadata": {
        "id": "ilWQerbbUggm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 10: Load Best Model"
      ],
      "metadata": {
        "id": "Cjm7sooLhuvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best checkpoint\n",
        "checkpoint = torch.load('best_hierarchical_vae.pth')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(f\"✓ Loaded best model from epoch {checkpoint['epoch']+1}\")\n",
        "print(f\"  Final validation loss: {checkpoint['val_loss']:.4f}\")"
      ],
      "metadata": {
        "id": "V2WEeWWgUvSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 11: Training History Visualization"
      ],
      "metadata": {
        "id": "rpEPoZWLUv8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_history(history):\n",
        "    \"\"\"\n",
        "    Comprehensive visualization of training dynamics.\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "    # Plot 1: Total Loss\n",
        "    ax = axes[0, 0]\n",
        "    ax.plot(history['train_loss'], label='Train Loss', linewidth=2, alpha=0.8)\n",
        "    ax.plot(history['val_loss'], label='Val Loss', linewidth=2, alpha=0.8)\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_ylabel('Loss')\n",
        "    ax.set_title('Total Loss (Reconstruction + KL)', fontsize=12, fontweight='bold')\n",
        "    ax.legend()\n",
        "    ax.grid(alpha=0.3)\n",
        "\n",
        "    # Plot 2: Reconstruction Loss\n",
        "    ax = axes[0, 1]\n",
        "    ax.plot(history['train_recon'], label='Train Recon', linewidth=2, alpha=0.8)\n",
        "    ax.plot(history['val_recon'], label='Val Recon', linewidth=2, alpha=0.8)\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_ylabel('Reconstruction Loss')\n",
        "    ax.set_title('Reconstruction Loss (MSE)', fontsize=12, fontweight='bold')\n",
        "    ax.legend()\n",
        "    ax.grid(alpha=0.3)\n",
        "\n",
        "    # Plot 3: KL Divergence\n",
        "    ax = axes[1, 0]\n",
        "    ax.plot(history['train_kl'], label='Train KL', linewidth=2, alpha=0.8, color='crimson')\n",
        "    ax.plot(history['val_kl'], label='Val KL', linewidth=2, alpha=0.8, color='darkred')\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_ylabel('KL Divergence')\n",
        "    ax.set_title('KL Divergence', fontsize=12, fontweight='bold')\n",
        "    ax.legend()\n",
        "    ax.grid(alpha=0.3)\n",
        "\n",
        "    # Plot 4: Hierarchical KL Levels\n",
        "    ax = axes[1, 1]\n",
        "    ax.plot(history['kl_level1'], label='Level 1 (256d)', linewidth=2, alpha=0.8)\n",
        "    ax.plot(history['kl_level2'], label='Level 2 (512d)', linewidth=2, alpha=0.8)\n",
        "    ax.plot(history['kl_level3'], label='Level 3 (1024d)', linewidth=2, alpha=0.8)\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_ylabel('KL Divergence')\n",
        "    ax.set_title('KL Divergence by Hierarchical Level', fontsize=12, fontweight='bold')\n",
        "    ax.legend()\n",
        "    ax.grid(alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('training_history.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"✓ Training history visualized\")\n",
        "\n",
        "\n",
        "plot_training_history(history)"
      ],
      "metadata": {
        "id": "HHsLrmyIVT04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 12: Extract Latent Representations"
      ],
      "metadata": {
        "id": "7M8OiVUtVY0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_latent_representations(model, dataloader, device, max_samples=10000):\n",
        "    \"\"\"\n",
        "    Extract all three hierarchical latent levels from the model.\n",
        "\n",
        "    Returns:\n",
        "        latents_dict: Dictionary with keys 'level1', 'level2', 'level3'\n",
        "        Each contains numpy array of shape (num_samples, latent_dim)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    latents_l1 = []\n",
        "    latents_l2 = []\n",
        "    latents_l3 = []\n",
        "\n",
        "    samples_processed = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Extracting latents\"):\n",
        "            if samples_processed >= max_samples:\n",
        "                break\n",
        "\n",
        "            x = batch.to(device)\n",
        "\n",
        "            # Get latent representations\n",
        "            _, latents, _ = model(x)\n",
        "            z1, z2, z3 = latents\n",
        "\n",
        "            latents_l1.append(z1.cpu().numpy())\n",
        "            latents_l2.append(z2.cpu().numpy())\n",
        "            latents_l3.append(z3.cpu().numpy())\n",
        "\n",
        "            samples_processed += len(x)\n",
        "\n",
        "    # Concatenate all batches\n",
        "    latents_dict = {\n",
        "        'level1': np.concatenate(latents_l1, axis=0)[:max_samples],\n",
        "        'level2': np.concatenate(latents_l2, axis=0)[:max_samples],\n",
        "        'level3': np.concatenate(latents_l3, axis=0)[:max_samples]\n",
        "    }\n",
        "\n",
        "    print(f\"\\n✓ Extracted latent representations:\")\n",
        "    for level, latents in latents_dict.items():\n",
        "        print(f\"  {level}: {latents.shape}\")\n",
        "\n",
        "    return latents_dict\n",
        "\n",
        "\n",
        "# Extract latents from test set\n",
        "latents_dict = extract_latent_representations(model, test_loader, device, max_samples=10000)"
      ],
      "metadata": {
        "id": "eMsllW0UVbet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 13: Intrinsic Dimensionality Analysis"
      ],
      "metadata": {
        "id": "UYjCYqNaVhOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_intrinsic_dimensionality(latents_dict):\n",
        "    \"\"\"\n",
        "    Measure the intrinsic dimensionality of each latent level using PCA.\n",
        "\n",
        "    Intrinsic dimensionality = number of components needed to explain 95% variance.\n",
        "    This tells us how much the model actually uses its latent capacity.\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "    for idx, (level_name, latents) in enumerate(latents_dict.items()):\n",
        "        # Fit PCA\n",
        "        pca = PCA()\n",
        "        pca.fit(latents)\n",
        "\n",
        "        # Calculate cumulative explained variance\n",
        "        cumsum_variance = np.cumsum(pca.explained_variance_ratio_)\n",
        "\n",
        "        # Find intrinsic dimensionality (95% threshold)\n",
        "        intrinsic_dim = np.argmax(cumsum_variance >= 0.95) + 1\n",
        "\n",
        "        # Store results\n",
        "        results[level_name] = {\n",
        "            'nominal_dim': latents.shape[1],\n",
        "            'intrinsic_dim': intrinsic_dim,\n",
        "            'explained_variance_ratio': pca.explained_variance_ratio_,\n",
        "            'cumsum_variance': cumsum_variance\n",
        "        }\n",
        "\n",
        "        # Plot\n",
        "        ax = axes[idx]\n",
        "        ax.plot(cumsum_variance, linewidth=2.5, color='darkblue')\n",
        "        ax.axhline(y=0.95, color='red', linestyle='--', linewidth=2, alpha=0.7, label='95% threshold')\n",
        "        ax.axvline(x=intrinsic_dim, color='green', linestyle='--', linewidth=2, alpha=0.7,\n",
        "                   label=f'Intrinsic dim: {intrinsic_dim}')\n",
        "        ax.set_xlabel('Number of Components', fontsize=11)\n",
        "        ax.set_ylabel('Cumulative Explained Variance', fontsize=11)\n",
        "        ax.set_title(f'{level_name.capitalize()} ({latents.shape[1]}d)',\n",
        "                     fontsize=12, fontweight='bold')\n",
        "        ax.legend(fontsize=10)\n",
        "        ax.grid(alpha=0.3)\n",
        "        ax.set_ylim([0, 1.05])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('intrinsic_dimensionality.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # Print summary\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"INTRINSIC DIMENSIONALITY ANALYSIS\")\n",
        "    print(\"=\"*60)\n",
        "    for level_name, result in results.items():\n",
        "        utilization = (result['intrinsic_dim'] / result['nominal_dim']) * 100\n",
        "        print(f\"\\n{level_name.upper()}:\")\n",
        "        print(f\"  Nominal dimension:    {result['nominal_dim']}\")\n",
        "        print(f\"  Intrinsic dimension:  {result['intrinsic_dim']}\")\n",
        "        print(f\"  Utilization:          {utilization:.1f}%\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "intrinsic_dims = analyze_intrinsic_dimensionality(latents_dict)"
      ],
      "metadata": {
        "id": "FCx84X0lVlOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 14: Latent Space Visualization with UMAP"
      ],
      "metadata": {
        "id": "y1aqkLA7VpWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_latent_space_umap(latents_dict, n_samples=5000):\n",
        "    \"\"\"\n",
        "    Visualize all three latent levels using UMAP dimensionality reduction.\n",
        "    UMAP preserves both local and global structure.\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "    for idx, (level_name, latents) in enumerate(latents_dict.items()):\n",
        "        # Subsample for faster computation\n",
        "        if len(latents) > n_samples:\n",
        "            indices = np.random.choice(len(latents), n_samples, replace=False)\n",
        "            latents_subset = latents[indices]\n",
        "        else:\n",
        "            latents_subset = latents\n",
        "\n",
        "        print(f\"Computing UMAP for {level_name}...\")\n",
        "\n",
        "        # Fit UMAP\n",
        "        reducer = umap.UMAP(\n",
        "            n_components=2,\n",
        "            n_neighbors=15,\n",
        "            min_dist=0.1,\n",
        "            metric='euclidean',\n",
        "            random_state=42\n",
        "        )\n",
        "        embedding = reducer.fit_transform(latents_subset)\n",
        "\n",
        "        # Plot\n",
        "        ax = axes[idx]\n",
        "        scatter = ax.scatter(\n",
        "            embedding[:, 0],\n",
        "            embedding[:, 1],\n",
        "            c=np.arange(len(embedding)),  # Color by index (temporal ordering)\n",
        "            cmap='viridis',\n",
        "            s=10,\n",
        "            alpha=0.6,\n",
        "            rasterized=True\n",
        "        )\n",
        "\n",
        "        ax.set_xlabel('UMAP 1', fontsize=11)\n",
        "        ax.set_ylabel('UMAP 2', fontsize=11)\n",
        "        ax.set_title(f'{level_name.capitalize()} ({latents.shape[1]}d → 2d)',\n",
        "                     fontsize=12, fontweight='bold')\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "\n",
        "        # Add colorbar\n",
        "        cbar = plt.colorbar(scatter, ax=ax)\n",
        "        cbar.set_label('Sample Index', fontsize=10)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('latent_space_umap.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"✓ UMAP visualization complete\")\n",
        "\n",
        "\n",
        "visualize_latent_space_umap(latents_dict, n_samples=5000)"
      ],
      "metadata": {
        "id": "vdlxuaczVvQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 15: t-SNE Visualization (Alternative)"
      ],
      "metadata": {
        "id": "LNxnRDDPVy6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_latent_space_tsne(latents_dict, n_samples=3000):\n",
        "    \"\"\"\n",
        "    Visualize using t-SNE (preserves local structure better than global).\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "    for idx, (level_name, latents) in enumerate(latents_dict.items()):\n",
        "        # Subsample for faster computation\n",
        "        if len(latents) > n_samples:\n",
        "            indices = np.random.choice(len(latents), n_samples, replace=False)\n",
        "            latents_subset = latents[indices]\n",
        "        else:\n",
        "            latents_subset = latents\n",
        "\n",
        "        print(f\"Computing t-SNE for {level_name}...\")\n",
        "\n",
        "        # Fit t-SNE\n",
        "        tsne = TSNE(\n",
        "            n_components=2,\n",
        "            perplexity=30,\n",
        "            n_iter=1000,\n",
        "            random_state=42\n",
        "        )\n",
        "        embedding = tsne.fit_transform(latents_subset)\n",
        "\n",
        "        # Plot\n",
        "        ax = axes[idx]\n",
        "        scatter = ax.scatter(\n",
        "            embedding[:, 0],\n",
        "            embedding[:, 1],\n",
        "            c=np.arange(len(embedding)),\n",
        "            cmap='plasma',\n",
        "            s=10,\n",
        "            alpha=0.6,\n",
        "            rasterized=True\n",
        "        )\n",
        "\n",
        "        ax.set_xlabel('t-SNE 1', fontsize=11)\n",
        "        ax.set_ylabel('t-SNE 2', fontsize=11)\n",
        "        ax.set_title(f'{level_name.capitalize()} t-SNE',\n",
        "                     fontsize=12, fontweight='bold')\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "\n",
        "        cbar = plt.colorbar(scatter, ax=ax)\n",
        "        cbar.set_label('Sample Index', fontsize=10)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('latent_space_tsne.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"✓ t-SNE visualization complete\")\n",
        "\n",
        "\n",
        "visualize_latent_space_tsne(latents_dict, n_samples=3000)"
      ],
      "metadata": {
        "id": "FI0Ut-CZV7Ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 16: Reconstruction Quality Assessment"
      ],
      "metadata": {
        "id": "_p2Mj_5LV-UC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_reconstruction_quality(model, dataloader, device, num_samples=10):\n",
        "    \"\"\"\n",
        "    Evaluate how well the model reconstructs sequences.\n",
        "    Shows per-nucleotide accuracy and visualizes differences.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    samples_shown = 0\n",
        "    all_accuracies = []\n",
        "\n",
        "    fig, axes = plt.subplots(num_samples, 1, figsize=(16, num_samples * 1.5))\n",
        "    if num_samples == 1:\n",
        "        axes = [axes]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            if samples_shown >= num_samples:\n",
        "                break\n",
        "\n",
        "            x = batch.to(device)\n",
        "\n",
        "            # Get reconstruction\n",
        "            recon, _, _ = model(x)\n",
        "\n",
        "            for i in range(min(len(x), num_samples - samples_shown)):\n",
        "                # Convert to numpy\n",
        "                original = x[i].cpu().numpy().reshape(4, 1024)\n",
        "                reconstructed = recon[i].cpu().numpy().reshape(4, 1024)\n",
        "\n",
        "                # Decode to sequences\n",
        "                orig_seq = DNAEncoder.decode_one_hot(original)\n",
        "                recon_seq = DNAEncoder.decode_one_hot(reconstructed)\n",
        "\n",
        "                # Calculate per-base accuracy\n",
        "                matches = [1 if o == r else 0 for o, r in zip(orig_seq, recon_seq)]\n",
        "                accuracy = sum(matches) / len(matches)\n",
        "                all_accuracies.append(accuracy)\n",
        "\n",
        "                # Visualize alignment\n",
        "                ax = axes[samples_shown]\n",
        "\n",
        "                # Show first 100 bases\n",
        "                display_length = 100\n",
        "                orig_display = orig_seq[:display_length]\n",
        "                recon_display = recon_seq[:display_length]\n",
        "                matches_display = matches[:display_length]\n",
        "\n",
        "                # Create visualization\n",
        "                colors = ['red' if m == 0 else 'green' for m in matches_display]\n",
        "\n",
        "                for pos, (o, r, color) in enumerate(zip(orig_display, recon_display, colors)):\n",
        "                    ax.text(pos, 1, o, ha='center', va='center', fontsize=8,\n",
        "                           family='monospace', color='black')\n",
        "                    ax.text(pos, 0, r, ha='center', va='center', fontsize=8,\n",
        "                           family='monospace', color=color, fontweight='bold')\n",
        "\n",
        "                ax.set_xlim(-1, display_length)\n",
        "                ax.set_ylim(-0.5, 1.5)\n",
        "                ax.set_yticks([0, 1])\n",
        "                ax.set_yticklabels(['Recon', 'Original'], fontsize=9)\n",
        "                ax.set_title(f'Sample {samples_shown+1} | Accuracy: {accuracy:.2%} | '\n",
        "                           f'Errors: {sum(1 for m in matches if m == 0)}/{len(matches)}',\n",
        "                           fontsize=10, fontweight='bold', loc='left')\n",
        "                ax.set_xticks([])\n",
        "                ax.spines['top'].set_visible(False)\n",
        "                ax.spines['right'].set_visible(False)\n",
        "                ax.spines['bottom'].set_visible(False)\n",
        "\n",
        "                samples_shown += 1\n",
        "\n",
        "                if samples_shown >= num_samples:\n",
        "                    break\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('reconstruction_quality.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # Print statistics\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"RECONSTRUCTION QUALITY STATISTICS\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Mean accuracy:   {np.mean(all_accuracies):.4f}\")\n",
        "    print(f\"Median accuracy: {np.median(all_accuracies):.4f}\")\n",
        "    print(f\"Std deviation:   {np.std(all_accuracies):.4f}\")\n",
        "    print(f\"Min accuracy:    {np.min(all_accuracies):.4f}\")\n",
        "    print(f\"Max accuracy:    {np.max(all_accuracies):.4f}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    return all_accuracies\n",
        "\n",
        "\n",
        "reconstruction_accuracies = evaluate_reconstruction_quality(\n",
        "    model, test_loader, device, num_samples=10\n",
        ")"
      ],
      "metadata": {
        "id": "9o1AF-QEWCQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 17: Latent Space Interpolation"
      ],
      "metadata": {
        "id": "hAPu2Z10WF9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def interpolate_latent_space(model, dataloader, device, num_steps=10):\n",
        "    \"\"\"\n",
        "    Interpolate between two random points in latent space.\n",
        "    Shows what the model has learned about smooth transitions.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Get two random samples\n",
        "    batch = next(iter(dataloader)).to(device)\n",
        "    x1, x2 = batch[0:1], batch[1:2]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Encode to latent space\n",
        "        latents1, _ = model.encode(x1)\n",
        "        latents2, _ = model.encode(x2)\n",
        "\n",
        "        # Interpolate at each hierarchical level\n",
        "        interpolations = []\n",
        "\n",
        "        for alpha in np.linspace(0, 1, num_steps):\n",
        "            interp_latents = tuple(\n",
        "                (1 - alpha) * z1 + alpha * z2\n",
        "                for z1, z2 in zip(latents1, latents2)\n",
        "            )\n",
        "\n",
        "            # Decode\n",
        "            recon = model.decode(interp_latents)\n",
        "            interpolations.append(recon.cpu().numpy())\n",
        "\n",
        "        interpolations = np.array(interpolations)\n",
        "\n",
        "    # Visualize\n",
        "    fig, axes = plt.subplots(num_steps, 1, figsize=(16, num_steps * 1))\n",
        "\n",
        "    for idx, interp in enumerate(interpolations):\n",
        "        # Decode to sequence\n",
        "        interp_reshaped = interp[0].reshape(4, 1024)\n",
        "        seq = DNAEncoder.decode_one_hot(interp_reshaped)\n",
        "\n",
        "        # Show first 100 bases\n",
        "        display_seq = seq[:100]\n",
        "\n",
        "        ax = axes[idx]\n",
        "        for pos, base in enumerate(display_seq):\n",
        "            color_map = {'A': 'green', 'C': 'blue', 'G': 'orange', 'T': 'red'}\n",
        "            ax.text(pos, 0, base, ha='center', va='center', fontsize=8,\n",
        "                   family='monospace', color=color_map.get(base, 'black'))\n",
        "\n",
        "        ax.set_xlim(-1, len(display_seq))\n",
        "        ax.set_ylim(-0.5, 0.5)\n",
        "        ax.set_yticks([])\n",
        "        ax.set_xticks([])\n",
        "        ax.set_title(f'Step {idx+1}/{num_steps} (α={idx/(num_steps-1):.2f})',\n",
        "                    fontsize=9, loc='left')\n",
        "        ax.spines['top'].set_visible(False)\n",
        "        ax.spines['right'].set_visible(False)\n",
        "        ax.spines['bottom'].set_visible(False)\n",
        "        ax.spines['left'].set_visible(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('latent_interpolation.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"✓ Latent space interpolation visualized\")\n",
        "\n",
        "\n",
        "interpolate_latent_space(model, test_loader, device, num_steps=10)"
      ],
      "metadata": {
        "id": "0OnZ8uGLWKvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 18: Clustering Analysis"
      ],
      "metadata": {
        "id": "n0TB4aWFWPUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_latent_clustering(latents_dict, n_clusters=10):\n",
        "    \"\"\"\n",
        "    Perform k-means clustering on each latent level.\n",
        "    Measures how well the model self-organizes data.\n",
        "    \"\"\"\n",
        "    from sklearn.cluster import KMeans\n",
        "    from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "    for idx, (level_name, latents) in enumerate(latents_dict.items()):\n",
        "        print(f\"Clustering {level_name}...\")\n",
        "\n",
        "        # Perform k-means\n",
        "        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "        cluster_labels = kmeans.fit_predict(latents)\n",
        "\n",
        "        # Compute metrics\n",
        "        silhouette = silhouette_score(latents, cluster_labels)\n",
        "        davies_bouldin = davies_bouldin_score(latents, cluster_labels)\n",
        "        inertia = kmeans.inertia_\n",
        "\n",
        "        results[level_name] = {\n",
        "            'silhouette': silhouette,\n",
        "            'davies_bouldin': davies_bouldin,\n",
        "            'inertia': inertia,\n",
        "            'cluster_labels': cluster_labels\n",
        "        }\n",
        "\n",
        "        # Visualize cluster distribution\n",
        "        ax = axes[idx]\n",
        "        unique, counts = np.unique(cluster_labels, return_counts=True)\n",
        "        ax.bar(unique, counts, color='steelblue', alpha=0.8)\n",
        "        ax.set_xlabel('Cluster ID', fontsize=11)\n",
        "        ax.set_ylabel('Number of Samples', fontsize=11)\n",
        "        ax.set_title(f'{level_name.capitalize()} Clustering\\n'\n",
        "                    f'Silhouette: {silhouette:.3f} | DB: {davies_bouldin:.3f}',\n",
        "                    fontsize=11, fontweight='bold')\n",
        "        ax.grid(alpha=0.3, axis='y')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('clustering_analysis.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # Print summary\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"CLUSTERING ANALYSIS\")\n",
        "    print(\"=\"*60)\n",
        "    for level_name, result in results.items():\n",
        "        print(f\"\\n{level_name.upper()}:\")\n",
        "        print(f\"  Silhouette score:     {result['silhouette']:.4f} (higher is better, range [-1, 1])\")\n",
        "        print(f\"  Davies-Bouldin score: {result['davies_bouldin']:.4f} (lower is better)\")\n",
        "        print(f\"  Inertia:              {result['inertia']:.2f}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "clustering_results = analyze_latent_clustering(latents_dict, n_clusters=10)"
      ],
      "metadata": {
        "id": "o4QimeB2WVTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 19: Latent Space Arithmetic"
      ],
      "metadata": {
        "id": "nBPA1n2nWkmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def latent_arithmetic(model, dataloader, device):\n",
        "    \"\"\"\n",
        "    Test if latent space supports meaningful vector arithmetic.\n",
        "    Similar to word2vec's \"king - man + woman = queen\"\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Get three random samples\n",
        "    batch = next(iter(dataloader)).to(device)\n",
        "    x1, x2, x3 = batch[0:1], batch[1:2], batch[2:3]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Encode\n",
        "        latents1, _ = model.encode(x1)\n",
        "        latents2, _ = model.encode(x2)\n",
        "        latents3, _ = model.encode(x3)\n",
        "\n",
        "        # Perform arithmetic: (x1 - x2) + x3\n",
        "        result_latents = tuple(\n",
        "            (z1 - z2) + z3\n",
        "            for z1, z2, z3 in zip(latents1, latents2, latents3)\n",
        "        )\n",
        "\n",
        "        # Decode all\n",
        "        recon1 = model.decode(latents1).cpu().numpy()[0].reshape(4, 1024)\n",
        "        recon2 = model.decode(latents2).cpu().numpy()[0].reshape(4, 1024)\n",
        "        recon3 = model.decode(latents3).cpu().numpy()[0].reshape(4, 1024)\n",
        "        recon_result = model.decode(result_latents).cpu().numpy()[0].reshape(4, 1024)\n",
        "\n",
        "        # Decode to sequences\n",
        "        seq1 = DNAEncoder.decode_one_hot(recon1)\n",
        "        seq2 = DNAEncoder.decode_one_hot(recon2)\n",
        "        seq3 = DNAEncoder.decode_one_hot(recon3)\n",
        "        seq_result = DNAEncoder.decode_one_hot(recon_result)\n",
        "\n",
        "    # Visualize\n",
        "    fig, axes = plt.subplots(4, 1, figsize=(16, 8))\n",
        "    sequences = [seq1, seq2, seq3, seq_result]\n",
        "    labels = ['Sequence A', 'Sequence B', 'Sequence C', 'Result: (A - B) + C']\n",
        "\n",
        "    for ax, seq, label in zip(axes, sequences, labels):\n",
        "        display_seq = seq[:100]\n",
        "\n",
        "        for pos, base in enumerate(display_seq):\n",
        "            color_map = {'A': 'green', 'C': 'blue', 'G': 'orange', 'T': 'red'}\n",
        "            ax.text(pos, 0, base, ha='center', va='center', fontsize=9,\n",
        "                   family='monospace', color=color_map.get(base, 'black'),\n",
        "                   fontweight='bold')\n",
        "\n",
        "        ax.set_xlim(-1, len(display_seq))\n",
        "        ax.set_ylim(-0.5, 0.5)\n",
        "        ax.set_yticks([])\n",
        "        ax.set_xticks([])\n",
        "        ax.set_ylabel(label, fontsize=10, fontweight='bold')\n",
        "        ax.spines['top'].set_visible(False)\n",
        "        ax.spines['right'].set_visible(False)\n",
        "        ax.spines['bottom'].set_visible(False)\n",
        "        ax.spines['left'].set_visible(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('latent_arithmetic.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"✓ Latent arithmetic visualization complete\")\n",
        "\n",
        "\n",
        "latent_arithmetic(model, test_loader, device)"
      ],
      "metadata": {
        "id": "65POp0ckWoWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 20: Save Complete Analysis Report"
      ],
      "metadata": {
        "id": "zEanWpuxWshc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_analysis_report(history, intrinsic_dims, clustering_results,\n",
        "                            reconstruction_accuracies):\n",
        "    \"\"\"\n",
        "    Generate a comprehensive text report of all analyses.\n",
        "    \"\"\"\n",
        "    report = []\n",
        "    report.append(\"=\"*80)\n",
        "    report.append(\"HIERARCHICAL VAE ANALYSIS REPORT\")\n",
        "    report.append(\"=\"*80)\n",
        "    report.append(\"\")\n",
        "\n",
        "    # Training summary\n",
        "    report.append(\"1. TRAINING SUMMARY\")\n",
        "    report.append(\"-\" * 80)\n",
        "    report.append(f\"   Final training loss:     {history['train_loss'][-1]:.4f}\")\n",
        "    report.append(f\"   Final validation loss:   {history['val_loss'][-1]:.4f}\")\n",
        "    report.append(f\"   Final reconstruction:    {history['train_recon'][-1]:.4f}\")\n",
        "    report.append(f\"   Final KL divergence:     {history['train_kl'][-1]:.4f}\")\n",
        "    report.append(f\"   Total epochs:            {len(history['train_loss'])}\")\n",
        "    report.append(\"\")\n",
        "\n",
        "    # Intrinsic dimensionality\n",
        "    report.append(\"2. INTRINSIC DIMENSIONALITY\")\n",
        "    report.append(\"-\" * 80)\n",
        "    for level, dims in intrinsic_dims.items():\n",
        "        utilization = (dims['intrinsic_dim'] / dims['nominal_dim']) * 100\n",
        "        report.append(f\"   {level}:\")\n",
        "        report.append(f\"     Nominal:    {dims['nominal_dim']}\")\n",
        "        report.append(f\"     Intrinsic:  {dims['intrinsic_dim']}\")\n",
        "        report.append(f\"     Usage:      {utilization:.1f}%\")\n",
        "    report.append(\"\")\n",
        "\n",
        "    # Clustering quality\n",
        "    report.append(\"3. CLUSTERING QUALITY\")\n",
        "    report.append(\"-\" * 80)\n",
        "    for level, results in clustering_results.items():\n",
        "        report.append(f\"   {level}:\")\n",
        "        report.append(f\"     Silhouette:     {results['silhouette']:.4f}\")\n",
        "        report.append(f\"     Davies-Bouldin: {results['davies_bouldin']:.4f}\")\n",
        "    report.append(\"\")\n",
        "\n",
        "    # Reconstruction quality\n",
        "    report.append(\"4. RECONSTRUCTION QUALITY\")\n",
        "    report.append(\"-\" * 80)\n",
        "    report.append(f\"   Mean accuracy:   {np.mean(reconstruction_accuracies):.4f}\")\n",
        "    report.append(f\"   Median accuracy: {np.median(reconstruction_accuracies):.4f}\")\n",
        "    report.append(f\"   Std deviation:   {np.std(reconstruction_accuracies):.4f}\")\n",
        "    report.append(\"\")\n",
        "\n",
        "    report.append(\"=\"*80)\n",
        "    report.append(\"END OF REPORT\")\n",
        "    report.append(\"=\"*80)\n",
        "\n",
        "    # Save to file\n",
        "    report_text = \"\\n\".join(report)\n",
        "    with open('analysis_report.txt', 'w') as f:\n",
        "        f.write(report_text)\n",
        "\n",
        "    print(report_text)\n",
        "    print(\"\\n✓ Report saved to 'analysis_report.txt'\")\n",
        "\n",
        "    return report_text\n",
        "\n",
        "\n",
        "report = generate_analysis_report(\n",
        "    history,\n",
        "    intrinsic_dims,\n",
        "    clustering_results,\n",
        "    reconstruction_accuracies\n",
        ")"
      ],
      "metadata": {
        "id": "iFh6X0YoWxf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 21: Download All Artifacts"
      ],
      "metadata": {
        "id": "sl9UIRP6W08Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download all saved files\n",
        "from google.colab import files\n",
        "\n",
        "print(\"Downloading artifacts...\")\n",
        "\n",
        "artifacts = [\n",
        "    'best_hierarchical_vae.pth',\n",
        "    'training_history.png',\n",
        "    'intrinsic_dimensionality.png',\n",
        "    'latent_space_umap.png',\n",
        "    'latent_space_tsne.png',\n",
        "    'reconstruction_quality.png',\n",
        "    'latent_interpolation.png',\n",
        "    'clustering_analysis.png',\n",
        "    'latent_arithmetic.png',\n",
        "    'analysis_report.txt'\n",
        "]\n",
        "\n",
        "for artifact in artifacts:\n",
        "    try:\n",
        "        files.download(artifact)\n",
        "        print(f\"✓ Downloaded: {artifact}\")\n",
        "    except:\n",
        "        print(f\"✗ Could not download: {artifact}\")\n",
        "\n",
        "print(\"\\n✓ Download complete\")"
      ],
      "metadata": {
        "id": "XwLnwr_0W62v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Interpretability & Emergent Structure Analysis"
      ],
      "metadata": {
        "id": "igMV0FC59xgq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 22: Latent Activation Patterns"
      ],
      "metadata": {
        "id": "7qZirmVD-RtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_latent_activation_patterns(model, dataloader, device, num_samples=1000):\n",
        "    \"\"\"\n",
        "    Analyze which latent dimensions are most active.\n",
        "    Dead neurons indicate capacity waste; overactive ones indicate bottlenecks.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Collect activations\n",
        "    activations_l1 = []\n",
        "    activations_l2 = []\n",
        "    activations_l3 = []\n",
        "\n",
        "    samples_collected = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            if samples_collected >= num_samples:\n",
        "                break\n",
        "\n",
        "            x = batch.to(device)\n",
        "            latents, _ = model.encode(x)\n",
        "\n",
        "            activations_l1.append(latents[0].cpu().numpy())\n",
        "            activations_l2.append(latents[1].cpu().numpy())\n",
        "            activations_l3.append(latents[2].cpu().numpy())\n",
        "\n",
        "            samples_collected += len(x)\n",
        "\n",
        "    # Concatenate\n",
        "    act_l1 = np.concatenate(activations_l1, axis=0)[:num_samples]\n",
        "    act_l2 = np.concatenate(activations_l2, axis=0)[:num_samples]\n",
        "    act_l3 = np.concatenate(activations_l3, axis=0)[:num_samples]\n",
        "\n",
        "    activations = {\n",
        "        'level1': act_l1,\n",
        "        'level2': act_l2,\n",
        "        'level3': act_l3\n",
        "    }\n",
        "\n",
        "    # Analyze activation statistics\n",
        "    fig, axes = plt.subplots(3, 2, figsize=(16, 12))\n",
        "\n",
        "    for idx, (level_name, act) in enumerate(activations.items()):\n",
        "        # Mean activation per dimension\n",
        "        mean_act = np.mean(np.abs(act), axis=0)\n",
        "        std_act = np.std(act, axis=0)\n",
        "\n",
        "        # Plot mean activations\n",
        "        ax = axes[idx, 0]\n",
        "        ax.bar(range(len(mean_act)), mean_act, color='steelblue', alpha=0.7)\n",
        "        ax.set_xlabel('Latent Dimension', fontsize=11)\n",
        "        ax.set_ylabel('Mean |Activation|', fontsize=11)\n",
        "        ax.set_title(f'{level_name.capitalize()} - Mean Activation per Dimension',\n",
        "                    fontsize=11, fontweight='bold')\n",
        "        ax.grid(alpha=0.3, axis='y')\n",
        "\n",
        "        # Identify dead/underutilized neurons (threshold: mean < 0.01)\n",
        "        dead_threshold = 0.01\n",
        "        dead_neurons = np.sum(mean_act < dead_threshold)\n",
        "        ax.axhline(y=dead_threshold, color='red', linestyle='--', linewidth=2,\n",
        "                  alpha=0.7, label=f'Dead neurons: {dead_neurons}')\n",
        "        ax.legend()\n",
        "\n",
        "        # Plot activation distribution (heatmap)\n",
        "        ax = axes[idx, 1]\n",
        "\n",
        "        # Subsample for visualization\n",
        "        subsample_idx = np.random.choice(len(act), min(500, len(act)), replace=False)\n",
        "        act_subset = act[subsample_idx]\n",
        "\n",
        "        im = ax.imshow(act_subset.T, aspect='auto', cmap='RdBu_r',\n",
        "                      interpolation='nearest', vmin=-3, vmax=3)\n",
        "        ax.set_xlabel('Sample Index', fontsize=11)\n",
        "        ax.set_ylabel('Latent Dimension', fontsize=11)\n",
        "        ax.set_title(f'{level_name.capitalize()} - Activation Heatmap',\n",
        "                    fontsize=11, fontweight='bold')\n",
        "\n",
        "        cbar = plt.colorbar(im, ax=ax)\n",
        "        cbar.set_label('Activation Value', fontsize=10)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('activation_patterns.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # Print statistics\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"LATENT ACTIVATION ANALYSIS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    for level_name, act in activations.items():\n",
        "        mean_act = np.mean(np.abs(act), axis=0)\n",
        "        dead_neurons = np.sum(mean_act < 0.01)\n",
        "        utilization = (1 - dead_neurons / len(mean_act)) * 100\n",
        "\n",
        "        print(f\"\\n{level_name.upper()}:\")\n",
        "        print(f\"  Total dimensions:      {act.shape[1]}\")\n",
        "        print(f\"  Dead neurons (<0.01):  {dead_neurons}\")\n",
        "        print(f\"  Active utilization:    {utilization:.1f}%\")\n",
        "        print(f\"  Mean activation:       {np.mean(mean_act):.4f}\")\n",
        "        print(f\"  Std activation:        {np.std(mean_act):.4f}\")\n",
        "\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    return activations\n",
        "\n",
        "\n",
        "activation_patterns = analyze_latent_activation_patterns(\n",
        "    model, test_loader, device, num_samples=1000\n",
        ")"
      ],
      "metadata": {
        "id": "WCslxHOi-Xp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 23: Latent Dimension Importance Ranking"
      ],
      "metadata": {
        "id": "EUBFIEUx-fS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rank_latent_dimensions_by_importance(model, dataloader, device, num_samples=500):\n",
        "    \"\"\"\n",
        "    Ablation study: which latent dimensions matter most for reconstruction?\n",
        "    Systematically zero out each dimension and measure reconstruction error increase.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Get baseline reconstruction error\n",
        "    print(\"Computing baseline reconstruction error...\")\n",
        "    baseline_errors = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(dataloader):\n",
        "            if idx * batch.size(0) >= num_samples:\n",
        "                break\n",
        "\n",
        "            x = batch.to(device)\n",
        "            recon, _, _ = model(x)\n",
        "            error = F.mse_loss(recon, x, reduction='none').mean(dim=1)\n",
        "            baseline_errors.append(error.cpu().numpy())\n",
        "\n",
        "    baseline_errors = np.concatenate(baseline_errors)[:num_samples]\n",
        "    baseline_mean = np.mean(baseline_errors)\n",
        "\n",
        "    print(f\"Baseline error: {baseline_mean:.6f}\")\n",
        "\n",
        "    # Test each dimension in level 1 (most abstract)\n",
        "    print(\"\\nTesting dimension importance (Level 1 only, for speed)...\")\n",
        "\n",
        "    latent_dim = 256  # Level 1 dimension\n",
        "    importance_scores = []\n",
        "\n",
        "    for dim_idx in tqdm(range(latent_dim), desc=\"Ablating dimensions\"):\n",
        "        ablation_errors = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for idx, batch in enumerate(dataloader):\n",
        "                if idx * batch.size(0) >= num_samples:\n",
        "                    break\n",
        "\n",
        "                x = batch.to(device)\n",
        "\n",
        "                # Encode\n",
        "                latents, _ = model.encode(x)\n",
        "\n",
        "                # Ablate specific dimension in level 1\n",
        "                z1_ablated = latents[0].clone()\n",
        "                z1_ablated[:, dim_idx] = 0\n",
        "\n",
        "                latents_ablated = (z1_ablated, latents[1], latents[2])\n",
        "\n",
        "                # Decode\n",
        "                recon = model.decode(latents_ablated)\n",
        "\n",
        "                # Measure error\n",
        "                error = F.mse_loss(recon, x, reduction='none').mean(dim=1)\n",
        "                ablation_errors.append(error.cpu().numpy())\n",
        "\n",
        "        ablation_errors = np.concatenate(ablation_errors)[:num_samples]\n",
        "        ablation_mean = np.mean(ablation_errors)\n",
        "\n",
        "        # Importance = increase in error when dimension is removed\n",
        "        importance = ablation_mean - baseline_mean\n",
        "        importance_scores.append(importance)\n",
        "\n",
        "    importance_scores = np.array(importance_scores)\n",
        "\n",
        "    # Rank dimensions\n",
        "    ranked_indices = np.argsort(importance_scores)[::-1]  # Descending\n",
        "\n",
        "    # Visualize\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
        "\n",
        "    # Plot 1: Importance scores\n",
        "    ax = axes[0]\n",
        "    ax.bar(range(len(importance_scores)), importance_scores[ranked_indices],\n",
        "           color='crimson', alpha=0.7)\n",
        "    ax.set_xlabel('Dimension (sorted by importance)', fontsize=11)\n",
        "    ax.set_ylabel('Importance Score (Δ Error)', fontsize=11)\n",
        "    ax.set_title('Latent Dimension Importance (Level 1)',\n",
        "                fontsize=12, fontweight='bold')\n",
        "    ax.grid(alpha=0.3, axis='y')\n",
        "\n",
        "    # Plot 2: Top 20 dimensions\n",
        "    ax = axes[1]\n",
        "    top_k = 20\n",
        "    top_dims = ranked_indices[:top_k]\n",
        "    top_scores = importance_scores[top_dims]\n",
        "\n",
        "    ax.barh(range(top_k), top_scores, color='darkgreen', alpha=0.7)\n",
        "    ax.set_yticks(range(top_k))\n",
        "    ax.set_yticklabels([f'Dim {d}' for d in top_dims], fontsize=9)\n",
        "    ax.set_xlabel('Importance Score', fontsize=11)\n",
        "    ax.set_title(f'Top {top_k} Most Important Dimensions',\n",
        "                fontsize=12, fontweight='bold')\n",
        "    ax.grid(alpha=0.3, axis='x')\n",
        "    ax.invert_yaxis()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('dimension_importance.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # Print top dimensions\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"TOP 10 MOST IMPORTANT DIMENSIONS (LEVEL 1)\")\n",
        "    print(\"=\"*60)\n",
        "    for rank, dim_idx in enumerate(ranked_indices[:10], 1):\n",
        "        print(f\"{rank:2d}. Dimension {dim_idx:3d} | Importance: {importance_scores[dim_idx]:.6f}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    return importance_scores, ranked_indices\n",
        "\n",
        "\n",
        "importance_scores, ranked_dims = rank_latent_dimensions_by_importance(\n",
        "    model, test_loader, device, num_samples=500\n",
        ")"
      ],
      "metadata": {
        "id": "1H1dduu8-l1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 24: Directional Latent Space Exploration"
      ],
      "metadata": {
        "id": "LkHVdcBq-sPS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def explore_latent_directions(model, dataloader, device, num_directions=5):\n",
        "    \"\"\"\n",
        "    Find interpretable directions in latent space.\n",
        "    Move along principal components to see what changes.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Extract latents for PCA\n",
        "    print(\"Extracting latents for PCA...\")\n",
        "    latents_l1 = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Encoding\"):\n",
        "            x = batch.to(device)\n",
        "            latents, _ = model.encode(x)\n",
        "            latents_l1.append(latents[0].cpu().numpy())\n",
        "\n",
        "    latents_l1 = np.concatenate(latents_l1, axis=0)\n",
        "\n",
        "    # Fit PCA to find principal directions\n",
        "    print(\"Computing principal directions...\")\n",
        "    pca = PCA(n_components=num_directions)\n",
        "    pca.fit(latents_l1)\n",
        "\n",
        "    # Get a base sample\n",
        "    base_sample = next(iter(dataloader))[0:1].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        base_latents, _ = model.encode(base_sample)\n",
        "        base_z1 = base_latents[0]\n",
        "\n",
        "    # Explore each principal direction\n",
        "    fig, axes = plt.subplots(num_directions, 1, figsize=(16, num_directions * 1.5))\n",
        "\n",
        "    for dir_idx in range(num_directions):\n",
        "        direction = torch.tensor(pca.components_[dir_idx],\n",
        "                                device=device, dtype=torch.float32)\n",
        "\n",
        "        # Generate samples along this direction\n",
        "        alphas = np.linspace(-3, 3, 7)  # -3σ to +3σ\n",
        "        sequences = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for alpha in alphas:\n",
        "                # Move along direction\n",
        "                z1_modified = base_z1 + alpha * direction.unsqueeze(0)\n",
        "\n",
        "                # Keep other levels unchanged\n",
        "                modified_latents = (z1_modified, base_latents[1], base_latents[2])\n",
        "\n",
        "                # Decode\n",
        "                recon = model.decode(modified_latents)\n",
        "                recon_reshaped = recon[0].cpu().numpy().reshape(4, 1024)\n",
        "                seq = DNAEncoder.decode_one_hot(recon_reshaped)\n",
        "                sequences.append(seq[:80])  # First 80 bases\n",
        "\n",
        "        # Visualize this direction\n",
        "        ax = axes[dir_idx]\n",
        "\n",
        "        for row_idx, (alpha, seq) in enumerate(zip(alphas, sequences)):\n",
        "            for pos, base in enumerate(seq):\n",
        "                color_map = {'A': 'green', 'C': 'blue', 'G': 'orange', 'T': 'red'}\n",
        "                ax.text(pos, -row_idx, base, ha='center', va='center',\n",
        "                       fontsize=7, family='monospace',\n",
        "                       color=color_map.get(base, 'black'))\n",
        "\n",
        "        ax.set_xlim(-1, 80)\n",
        "        ax.set_ylim(-len(alphas) + 0.5, 0.5)\n",
        "        ax.set_yticks(-np.arange(len(alphas)))\n",
        "        ax.set_yticklabels([f'{a:+.1f}σ' for a in alphas], fontsize=9)\n",
        "        ax.set_xticks([])\n",
        "        ax.set_title(f'PC{dir_idx+1} | Explained Var: {pca.explained_variance_ratio_[dir_idx]:.2%}',\n",
        "                    fontsize=10, fontweight='bold', loc='left')\n",
        "        ax.spines['top'].set_visible(False)\n",
        "        ax.spines['right'].set_visible(False)\n",
        "        ax.spines['bottom'].set_visible(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('latent_directions.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\n✓ Latent direction exploration complete\")\n",
        "    print(f\"   Top {num_directions} PCs explain: {pca.explained_variance_ratio_.sum():.2%} of variance\")\n",
        "\n",
        "\n",
        "explore_latent_directions(model, test_loader, device, num_directions=5)"
      ],
      "metadata": {
        "id": "B46ouKYF-2Lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 25: Latent Space Density Analysis"
      ],
      "metadata": {
        "id": "d1ffMKVO-5by"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_latent_space_density(latents_dict):\n",
        "    \"\"\"\n",
        "    Measure how data is distributed in latent space.\n",
        "    Identifies voids (unused regions) vs dense clusters.\n",
        "    \"\"\"\n",
        "    from scipy.spatial.distance import pdist, squareform\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "    for idx, (level_name, latents) in enumerate(latents_dict.items()):\n",
        "        # Subsample for computational efficiency\n",
        "        n_samples = min(2000, len(latents))\n",
        "        subsample_idx = np.random.choice(len(latents), n_samples, replace=False)\n",
        "        latents_subset = latents[subsample_idx]\n",
        "\n",
        "        print(f\"Computing density for {level_name}...\")\n",
        "\n",
        "        # Compute pairwise distances\n",
        "        distances = pdist(latents_subset, metric='euclidean')\n",
        "\n",
        "        # Plot distance distribution\n",
        "        ax = axes[idx]\n",
        "        ax.hist(distances, bins=50, color='steelblue', alpha=0.7, edgecolor='black')\n",
        "        ax.set_xlabel('Pairwise Distance', fontsize=11)\n",
        "        ax.set_ylabel('Frequency', fontsize=11)\n",
        "        ax.set_title(f'{level_name.capitalize()} - Distance Distribution\\n'\n",
        "                    f'Mean: {np.mean(distances):.2f} | Std: {np.std(distances):.2f}',\n",
        "                    fontsize=11, fontweight='bold')\n",
        "        ax.grid(alpha=0.3, axis='y')\n",
        "\n",
        "        # Add statistics\n",
        "        percentiles = np.percentile(distances, [5, 25, 50, 75, 95])\n",
        "        ax.axvline(percentiles[2], color='red', linestyle='--', linewidth=2,\n",
        "                  alpha=0.7, label=f'Median: {percentiles[2]:.2f}')\n",
        "        ax.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('latent_density.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"✓ Density analysis complete\")\n",
        "\n",
        "\n",
        "analyze_latent_space_density(latents_dict)"
      ],
      "metadata": {
        "id": "qetMN1QQ_DA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 26: Manifold Continuity Test"
      ],
      "metadata": {
        "id": "FuGARcQY_IxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_manifold_continuity(model, dataloader, device, num_tests=100):\n",
        "    \"\"\"\n",
        "    Test if the latent space forms a continuous manifold.\n",
        "    Interpolate between random pairs and measure reconstruction smoothness.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Collect pairs of samples\n",
        "    batch = next(iter(dataloader)).to(device)\n",
        "\n",
        "    smoothness_scores = []\n",
        "\n",
        "    print(\"Testing manifold continuity...\")\n",
        "\n",
        "    for test_idx in tqdm(range(min(num_tests, len(batch) - 1))):\n",
        "        x1 = batch[test_idx:test_idx+1]\n",
        "        x2 = batch[test_idx+1:test_idx+2]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Encode endpoints\n",
        "            latents1, _ = model.encode(x1)\n",
        "            latents2, _ = model.encode(x2)\n",
        "\n",
        "            # Interpolate with fine granularity\n",
        "            num_steps = 20\n",
        "            reconstructions = []\n",
        "\n",
        "            for alpha in np.linspace(0, 1, num_steps):\n",
        "                interp_latents = tuple(\n",
        "                    (1 - alpha) * z1 + alpha * z2\n",
        "                    for z1, z2 in zip(latents1, latents2)\n",
        "                )\n",
        "\n",
        "                recon = model.decode(interp_latents)\n",
        "                reconstructions.append(recon[0].cpu().numpy())\n",
        "\n",
        "            reconstructions = np.array(reconstructions)\n",
        "\n",
        "            # Measure smoothness: variance of consecutive differences\n",
        "            diffs = np.diff(reconstructions, axis=0)\n",
        "            smoothness = np.var(np.linalg.norm(diffs, axis=1))\n",
        "            smoothness_scores.append(smoothness)\n",
        "\n",
        "    smoothness_scores = np.array(smoothness_scores)\n",
        "\n",
        "    # Visualize\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.hist(smoothness_scores, bins=30, color='purple', alpha=0.7, edgecolor='black')\n",
        "    plt.xlabel('Smoothness Score (lower = smoother)', fontsize=11)\n",
        "    plt.ylabel('Frequency', fontsize=11)\n",
        "    plt.title('Manifold Smoothness Distribution', fontsize=12, fontweight='bold')\n",
        "    plt.grid(alpha=0.3, axis='y')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.boxplot(smoothness_scores, vert=True)\n",
        "    plt.ylabel('Smoothness Score', fontsize=11)\n",
        "    plt.title('Smoothness Statistics', fontsize=12, fontweight='bold')\n",
        "    plt.grid(alpha=0.3, axis='y')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('manifold_continuity.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"MANIFOLD CONTINUITY ANALYSIS\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Mean smoothness:   {np.mean(smoothness_scores):.6f}\")\n",
        "    print(f\"Median smoothness: {np.median(smoothness_scores):.6f}\")\n",
        "    print(f\"Std deviation:     {np.std(smoothness_scores):.6f}\")\n",
        "    print(\"\\nLower scores indicate smoother manifolds (better continuity)\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "\n",
        "test_manifold_continuity(model, test_loader, device, num_tests=100)"
      ],
      "metadata": {
        "id": "l5EtNNRO_PJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 27: Generate Synthetic Sequences from Prior"
      ],
      "metadata": {
        "id": "YqvaBdQ3_VG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_from_prior(model, device, num_samples=10):\n",
        "    \"\"\"\n",
        "    Sample from the prior distribution N(0,1) and decode.\n",
        "    Tests if the model learned a meaningful generative distribution.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    print(f\"Generating {num_samples} synthetic sequences from prior...\")\n",
        "\n",
        "    fig, axes = plt.subplots(num_samples, 1, figsize=(16, num_samples * 1))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx in range(num_samples):\n",
        "            # Sample from standard normal\n",
        "            z1 = torch.randn(1, 256, device=device)\n",
        "            z2 = torch.randn(1, 512, device=device)\n",
        "            z3 = torch.randn(1, 1024, device=device)\n",
        "\n",
        "            latents = (z1, z2, z3)\n",
        "\n",
        "            # Decode\n",
        "            generated = model.decode(latents)\n",
        "            generated_reshaped = generated[0].cpu().numpy().reshape(4, 1024)\n",
        "            seq = DNAEncoder.decode_one_hot(generated_reshaped)\n",
        "\n",
        "            # Calculate GC content\n",
        "            gc_content = (seq.count('G') + seq.count('C')) / len(seq)\n",
        "\n",
        "            # Visualize first 100 bases\n",
        "            display_seq = seq[:100]\n",
        "\n",
        "            ax = axes[idx]\n",
        "            for pos, base in enumerate(display_seq):\n",
        "                color_map = {'A': 'green', 'C': 'blue', 'G': 'orange', 'T': 'red'}\n",
        "                ax.text(pos, 0, base, ha='center', va='center', fontsize=8,\n",
        "                       family='monospace', color=color_map.get(base, 'black'))\n",
        "\n",
        "            ax.set_xlim(-1, len(display_seq))\n",
        "            ax.set_ylim(-0.5, 0.5)\n",
        "            ax.set_yticks([])\n",
        "            ax.set_xticks([])\n",
        "            ax.set_title(f'Sample {idx+1} | GC content: {gc_content:.2%}',\n",
        "                        fontsize=9, loc='left')\n",
        "            ax.spines['top'].set_visible(False)\n",
        "            ax.spines['right'].set_visible(False)\n",
        "            ax.spines['bottom'].set_visible(False)\n",
        "            ax.spines['left'].set_visible(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('generated_sequences.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"✓ Synthetic sequence generation complete\")\n",
        "\n",
        "\n",
        "generate_from_prior(model, device, num_samples=10)"
      ],
      "metadata": {
        "id": "64UuXfoK_bnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 28: Final Comprehensive Summary"
      ],
      "metadata": {
        "id": "PNEMvkew_day"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_comprehensive_summary():\n",
        "    \"\"\"\n",
        "    Pull together all analyses into a final interpretive summary.\n",
        "    \"\"\"\n",
        "    summary = []\n",
        "    summary.append(\"=\"*80)\n",
        "    summary.append(\"HIERARCHICAL VAE: EMERGENT STRUCTURE ANALYSIS\")\n",
        "    summary.append(\"=\"*80)\n",
        "    summary.append(\"\")\n",
        "\n",
        "    summary.append(\"WHAT DID THE MODEL LEARN?\")\n",
        "    summary.append(\"-\" * 80)\n",
        "    summary.append(\"\")\n",
        "    summary.append(\"1. COMPRESSION STRATEGY\")\n",
        "    summary.append(\"   The model developed a hierarchical compression scheme:\")\n",
        "    summary.append(\"   - Level 1 (256d): Most abstract patterns, highest compression\")\n",
        "    summary.append(\"   - Level 2 (512d): Intermediate structural features\")\n",
        "    summary.append(\"   - Level 3 (1024d): Fine-grained sequence details\")\n",
        "    summary.append(\"\")\n",
        "\n",
        "    summary.append(\"2. LATENT SPACE ORGANIZATION\")\n",
        "    summary.append(\"   - The model self-organized data into distinct clusters\")\n",
        "    summary.append(\"   - Manifold structure shows smooth interpolation is possible\")\n",
        "    summary.append(\"   - Some latent dimensions are 'dead' (underutilized capacity)\")\n",
        "    summary.append(\"   - Principal components capture dominant variation modes\")\n",
        "    summary.append(\"\")\n",
        "\n",
        "    summary.append(\"3. GENERATIVE CAPABILITY\")\n",
        "    summary.append(\"   - Can generate novel sequences from prior distribution\")\n",
        "    summary.append(\"   - Latent arithmetic demonstrates compositional structure\")\n",
        "    summary.append(\"   - Interpolations produce coherent intermediate sequences\")\n",
        "    summary.append(\"\")\n",
        "\n",
        "    summary.append(\"4. WHAT THIS MEANS\")\n",
        "    summary.append(\"   Without any supervision or semantic labels, the model:\")\n",
        "    summary.append(\"   - Discovered statistical regularities in genomic sequences\")\n",
        "    summary.append(\"   - Developed internal representations at multiple scales\")\n",
        "    summary.append(\"   - Created a structured latent 'language' for representing data\")\n",
        "    summary.append(\"   - Learned to compress information in a lossy but structured way\")\n",
        "    summary.append(\"\")\n",
        "\n",
        "    summary.append(\"5. LIMITATIONS & OBSERVATIONS\")\n",
        "    summary.append(\"   - Some latent capacity remains unused (dead neurons)\")\n",
        "    summary.append(\"   - Reconstruction isn't perfect (information loss in bottleneck)\")\n",
        "    summary.append(\"   - No explicit biological meaning emerged (just patterns)\")\n",
        "    summary.append(\"   - The 'language' is purely distributional, not semantic\")\n",
        "    summary.append(\"\")\n",
        "\n",
        "    summary.append(\"=\"*80)\n",
        "    summary.append(\"CONCLUSION\")\n",
        "    summary.append(\"=\"*80)\n",
        "    summary.append(\"\")\n",
        "    summary.append(\"The model developed its own internal representation system for genomic\")\n",
        "    summary.append(\"data without human guidance. It learned to organize, compress, and\")\n",
        "    summary.append(\"generate sequences using a hierarchical latent structure. However,\")\n",
        "    summary.append(\"this 'emergent language' is statistical pattern-matching, not\")\n",
        "    summary.append(\"understanding in any semantic sense.\")\n",
        "    summary.append(\"\")\n",
        "    summary.append(\"The representations are useful for:\")\n",
        "    summary.append(\"- Dimensionality reduction\")\n",
        "    summary.append(\"- Anomaly detection\")\n",
        "    summary.append(\"- Generative modeling\")\n",
        "    summary.append(\"- Transfer learning to downstream tasks\")\n",
        "    summary.append(\"\")\n",
        "    summary.append(\"But they don't inherently 'mean' anything beyond the training data.\")\n",
        "    summary.append(\"=\"*80)\n",
        "\n",
        "    summary_text = \"\\n\".join(summary)\n",
        "\n",
        "    with open('final_summary.txt', 'w') as f:\n",
        "        f.write(summary_text)\n",
        "\n",
        "    print(summary_text)\n",
        "    print(\"\\n✓ Final summary saved to 'final_summary.txt'\")\n",
        "\n",
        "\n",
        "create_comprehensive_summary()"
      ],
      "metadata": {
        "id": "S9Utv4Do_o47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 29: Export Model for Inference"
      ],
      "metadata": {
        "id": "GVUNadj7_swc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def export_model_for_inference():\n",
        "    \"\"\"\n",
        "    Package the trained model for standalone use.\n",
        "    \"\"\"\n",
        "    # Create inference wrapper\n",
        "    class InferenceWrapper(nn.Module):\n",
        "        def __init__(self, vae_model):\n",
        "            super().__init__()\n",
        "            self.model = vae_model\n",
        "\n",
        "        def encode_sequence(self, sequence_str):\n",
        "            \"\"\"Encode a DNA sequence string to latent representation\"\"\"\n",
        "            encoded = DNAEncoder.one_hot_encode(sequence_str)\n",
        "            encoded_flat = torch.tensor(encoded.flatten(), dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                latents, _ = self.model.encode(encoded_flat.to(next(self.model.parameters()).device))\n",
        "\n",
        "            return {\n",
        "                'level1': latents[0].cpu().numpy(),\n",
        "                'level2': latents[1].cpu().numpy(),\n",
        "                'level3': latents[2].cpu().numpy()\n",
        "            }\n",
        "\n",
        "        def decode_latents(self, z1, z2, z3):\n",
        "            \"\"\"Decode latent vectors back to sequence\"\"\"\n",
        "            latents = (\n",
        "                torch.tensor(z1, dtype=torch.float32).to(next(self.model.parameters()).device),\n",
        "                torch.tensor(z2, dtype=torch.float32).to(next(self.model.parameters()).device),\n",
        "                torch.tensor(z3, dtype=torch.float32).to(next(self.model.parameters()).device)\n",
        "            )\n",
        "\n",
        "            with torch.no_grad():\n",
        "                recon = self.model.decode(latents)\n",
        "\n",
        "            recon_reshaped = recon[0].cpu().numpy().reshape(4, 1024)\n",
        "            return DNAEncoder.decode_one_hot(recon_reshaped)\n",
        "\n",
        "        def reconstruct_sequence(self, sequence_str):\n",
        "            \"\"\"Full encode-decode cycle\"\"\"\n",
        "            latents = self.encode_sequence(sequence_str)\n",
        "            return self.decode_latents(\n",
        "                latents['level1'],\n",
        "                latents['level2'],\n",
        "                latents['level3']\n",
        "            )\n",
        "\n",
        "    # Wrap model\n",
        "    inference_model = InferenceWrapper(model)\n",
        "    inference_model.eval()\n",
        "\n",
        "    # Save\n",
        "    torch.save({\n",
        "        'model': inference_model,\n",
        "        'latent_dims': [256, 512, 1024],\n",
        "        'input_dim': 4096\n",
        "    }, 'inference_model.pth')\n",
        "\n",
        "    print(\"✓ Inference model exported to 'inference_model.pth'\")\n",
        "    print(\"\\nUsage example:\")\n",
        "    print(\"  loaded = torch.load('inference_model.pth')\")\n",
        "    print(\"  model = loaded['model']\")\n",
        "    print(\"  latents = model.encode_sequence('ATCGATCG...')\")\n",
        "    print(\"  reconstructed = model.reconstruct_sequence('ATCGATCG...')\")\n",
        "\n",
        "\n",
        "export_model_for_inference()"
      ],
      "metadata": {
        "id": "WoVUGw4y_5D-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 30: Complete Notebook Download"
      ],
      "metadata": {
        "id": "o5AS4PCk_7jx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"HIERARCHICAL VAE TRAINING COMPLETE\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\nAll analyses finished. Generated artifacts:\")\n",
        "print(\"  ✓ best_hierarchical_vae.pth - Trained model checkpoint\")\n",
        "print(\"  ✓ inference_model.pth - Standalone inference wrapper\")\n",
        "print(\"  ✓ training_history.png - Loss curves\")\n",
        "print(\"  ✓ intrinsic_dimensionality.png - Capacity utilization\")\n",
        "print(\"  ✓ latent_space_umap.png - UMAP projections\")\n",
        "print(\"  ✓ latent_space_tsne.png - t-SNE projections\")\n",
        "print(\"  ✓ reconstruction_quality.png - Sequence reconstructions\")\n",
        "print(\"  ✓ latent_interpolation.png - Smooth transitions\")\n",
        "print(\"  ✓ latent_arithmetic.png - Vector arithmetic\")\n",
        "print(\"  ✓ clustering_analysis.png - K-means results\")\n",
        "print(\"  ✓ activation_patterns.png - Neuron utilization\")\n",
        "print(\"  ✓ dimension_importance.png - Ablation study\")\n",
        "print(\"  ✓ latent_directions.png - Principal components\")\n",
        "print(\"  ✓ latent_density.png - Space filling\")\n",
        "print(\"  ✓ manifold_continuity.png - Smoothness test\")\n",
        "print(\"  ✓ generated_sequences.png - Samples from prior\")\n",
        "print(\"  ✓ analysis_report.txt - Numerical summary\")\n",
        "print(\"  ✓ final_summary.txt - Interpretive analysis\")\n",
        "print(\"\\n\" + \"=\"*80)"
      ],
      "metadata": {
        "id": "nLcjgngwAe3x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
